{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "oct_res.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpUBrgwpcoUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSwZYUlFcrog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing dataset\n",
        "!cp '/content/drive/My Drive/check.zip' '/content/'\n",
        "!unzip -q \"/content/check.zip\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apGphXTJcs7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch-lightning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHLiak_Ocs9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dependencies import *\n",
        "from models import *\n",
        "from IPython.display import display # to display images\n",
        "import torchvision.transforms.functional as TF\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP2d4WPGctBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyRotationTransform:\n",
        "    \"\"\"Rotate by one of the given angles.\"\"\"\n",
        "\n",
        "    def __init__(self, angles):\n",
        "        self.angles = angles\n",
        "\n",
        "    def __call__(self, x, mask):\n",
        "        angle = random.choice(self.angles)\n",
        "        mask = TF.rotate(mask, angle)\n",
        "        x = TF.rotate(x, angle, fill=(0,))\n",
        "      \n",
        "        return x, mask\n",
        "\n",
        "class brightTransform:\n",
        "    \"\"\"Rotate by one of the given angles.\"\"\"\n",
        "\n",
        "    def __init__(self, bightnesses):\n",
        "        self.bightnesses = bightnesses\n",
        "\n",
        "    def __call__(self, x):\n",
        "        bright = random.choice(self.bightnesses)\n",
        "        return TF.adjust_brightness(x, bright)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV8HEx6QctEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dataset\n",
        "class OCT_dataset(Dataset):\n",
        "    def __init__(self, root_dir, train=False):\n",
        "        self.root_dir = root_dir\n",
        "        self.train = train\n",
        "        self.imgs8bit_list = list(sorted(os.listdir(os.path.join(root_dir, \"8bit\"))))\n",
        "        self.black_targets_list = list(sorted(os.listdir(os.path.join(root_dir, \"black\"))))\n",
        "        self.rotation_transform = MyRotationTransform(angles=[-15, -7, 0, 7, 15])\n",
        "        self.bright_transform = brightTransform(bightnesses=[0.8, 0.87, 1, 1.12, 1.2])\n",
        "\n",
        "    def transform_dir(self, image, mask):\n",
        "        resize = T.Resize(size=(496, 523))\n",
        "        image = resize(image)\n",
        "        mask = resize(mask)\n",
        "        \n",
        "        #if self.train:\n",
        "        # Random horizontal flipping\n",
        "          #if random.random() > 0.75:\n",
        "            #image = TF.hflip(image)\n",
        "            #mask = TF.hflip(mask)\n",
        "          #if random.random() > 1.0:\n",
        "            #image, mask = self.rotation_transform(image, mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def transform_image(self, image):\n",
        "        toPIL = T.ToPILImage()\n",
        "        image = toPIL(image)\n",
        "\n",
        "        #if self.train:\n",
        "        #  if random.random() > 0.6:\n",
        "        #      image = self.bright_transform(image)\n",
        "\n",
        "        normalize = T.Normalize((0.5,), (0.5,))\n",
        "        image = TF.to_tensor(image)\n",
        "        image = normalize(image)\n",
        "        return image\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs8bit_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img8bit_instance_path = os.path.join(self.root_dir, \"8bit\", self.imgs8bit_list[idx])\n",
        "        black_target_instance_path = os.path.join(self.root_dir, \"black\", self.black_targets_list[idx])\n",
        "        \n",
        "        img8bit = Image.open(img8bit_instance_path)\n",
        "        black_target = Image.open(black_target_instance_path)\n",
        "        \n",
        "        img8bit, black_target = self.transform_dir(img8bit, black_target)\n",
        "        \n",
        "        img8bit = np.array(img8bit)\n",
        "        black_target = np.array(black_target)\n",
        "\n",
        "        unique_labels = np.unique(black_target) #probably 255\n",
        "        unique_label = unique_labels[1]\n",
        "        target_result = np.zeros((img8bit.shape[1]*3))\n",
        "\n",
        "        for i in range(3):\n",
        "            black_target_2dim = black_target[:, :, i]\n",
        "            val_255 = np.where(black_target_2dim == unique_label)\n",
        "            target_result[val_255[1] + i*523] = val_255[0]\n",
        "        \n",
        "        img8bit = self.transform_image(img8bit)\n",
        "        target_result = torch.from_numpy(target_result)\n",
        "        return img8bit, target_result, self.imgs8bit_list[idx]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wGAmr3IctHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Swish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Swish, self).__init__()\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "class ConvBlock(nn.Module):  # not exactly the same but inspired smth\n",
        "    def __init__(self, input_channels, output_channels, kernel, stride, projectile_dim):\n",
        "        super().__init__()\n",
        "        self.expand_cnn = nn.Conv2d(in_channels = input_channels, out_channels = output_channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(num_features = output_channels)\n",
        "\n",
        "        self.depthwise_conv = nn.Conv2d(in_channels = output_channels, out_channels = output_channels, groups=output_channels, kernel_size=kernel, stride = stride, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(num_features = output_channels)\n",
        "\n",
        "        self.add_reduce = nn.Conv2d(in_channels=output_channels, out_channels=int(output_channels/2), kernel_size=1)\n",
        "        self.add_expand = nn.Conv2d(in_channels=int(output_channels/2), out_channels=output_channels, kernel_size=1)\n",
        "\n",
        "        self.CNNnetwork = nn.Sequential(self.expand_cnn, self.bn1, self.depthwise_conv,self.bn2, self.add_reduce,  self.add_expand)\n",
        "\n",
        "        self.swish = Swish()\n",
        "\n",
        "        self.projectile = nn.Conv2d(in_channels=output_channels, out_channels=projectile_dim, kernel_size=1, bias=False)\n",
        "        #self.pool = nn.MaxPool2d(kernel_size = 2)\n",
        "        \n",
        "    def forward(self, data):\n",
        "        output = self.CNNnetwork(data)\n",
        "        output = self.swish(output)\n",
        "        project = self.projectile(output)\n",
        "        return output, project"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_8o8n2pc3mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNcheck(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, types = 'cnn'):\n",
        "        super().__init__()\n",
        "        self.types = types\n",
        "        if types == 'cnn':\n",
        "          self.CNNcell1 = CNNone(input_channels = 1, output_channels = 16)\n",
        "          self.CNNcell2 = CNNone(input_channels = 16, output_channels = 32)\n",
        "          self.CNNcell3 = CNNone(input_channels = 32, output_channels = 64)\n",
        "          self.CNNcell4 = CNNone(input_channels = 64, output_channels = 64)\n",
        "          self.CNNcell5 = CNNone(input_channels = 64, output_channels = 32)\n",
        "          self.CNNcell6 = CNNone(input_channels = 32, output_channels = 32)\n",
        "          #self.CNNcell7 = CNNone(input_channels = 32, output_channels = 16)\n",
        "          self.CNNnetwork = nn.Sequential(self.CNNcell1, self.CNNcell2, \n",
        "                    self.CNNcell3,self.CNNcell4,self.CNNcell5,self.CNNcell6)\n",
        "          self.fc1 = nn.Linear(in_features = 32*8*7, out_features = 2000)\n",
        "          self.dropout1 = nn.Dropout(0.5)\n",
        "          self.fc2 = nn.Linear(in_features = 2000,out_features = 523*3)\n",
        "        \n",
        "        elif types == \"att\":\n",
        "          self.CNNcell1 = ConvBlock(input_channels = 1, output_channels = 2, kernel = 3, stride = 2, projectile_dim = 2)\n",
        "          self.CNNcell2 = ConvBlock(input_channels = 2, output_channels = 4, kernel = 3, stride = 2, projectile_dim = 4)\n",
        "          self.CNNcell3 = ConvBlock(input_channels = 4, output_channels = 8, kernel = 3, stride = 2, projectile_dim = 8)\n",
        "          self.CNNcell4 = ConvBlock(input_channels = 8, output_channels = 16, kernel = 3, stride = 2, projectile_dim = 16)\n",
        "          self.CNNcell5 = ConvBlock(input_channels = 16, output_channels = 32, kernel = 3, stride = 2, projectile_dim = 32)\n",
        "          self.CNNcell6 = ConvBlock(input_channels = 32, output_channels = 64, kernel = 3, stride = 2, projectile_dim = 64)\n",
        "          \n",
        "          self.fc_attq = nn.Linear(in_features = 55520, out_features = 1000)\n",
        "          self.fc_attk = nn.Linear(in_features = 55520, out_features = 1000)\n",
        "          self.fc_attv =  nn.Linear(in_features = 55520, out_features = 1000)\n",
        "\n",
        "          self.fc = nn.Linear(in_features = 55520,out_features = 523*3)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.types == \"cnn\":\n",
        "          #x = x[:, None]\n",
        "          x = self.CNNnetwork(x)\n",
        "          x = x.view(-1, 32*8*7)\n",
        "          x = self.dropout1(self.fc1(x))\n",
        "          x = self.fc2(x)\n",
        "        \n",
        "        elif self.types == \"att\":\n",
        "          batch_size = x.size(0)\n",
        "          x, _ = self.CNNcell1(x)\n",
        "          x, _ = self.CNNcell2(x)\n",
        "          x, y1 = self.CNNcell3(x)\n",
        "          x, y2 = self.CNNcell4(x)\n",
        "          x, y3 = self.CNNcell5(x)\n",
        "          x, y4 = self.CNNcell6(x)\n",
        "          y1 = y1.view(batch_size, -1)\n",
        "          y2 = y2.view(batch_size, -1)\n",
        "          y3 = y3.view(batch_size, -1)\n",
        "          y4 = y4.view(batch_size, -1)   \n",
        "          out = torch.cat((y1, y2,y3, y4), dim=1)\n",
        "          q = self.fc_attq(out)\n",
        "          k = self.fc_attk(out)\n",
        "          v = self.fc_attv(out)\n",
        "\n",
        "          q = out[:, None]\n",
        "          k = out[:, None]\n",
        "          v = out[:, None]\n",
        "          attn_output_weights = torch.bmm(q, k.transpose(1, 2))\n",
        "          attn_output_weights = F.softmax(attn_output_weights, dim=-1)\n",
        "\n",
        "          x = torch.bmm(attn_output_weights, v)\n",
        "          x = x.view(batch_size, -1)\n",
        "          x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "    \n",
        "    def prepare_data(self):\n",
        "        dataset = OCT_dataset(path, train = True)\n",
        "        dataset_test = OCT_dataset(path, train = False)\n",
        "        \n",
        "        indices = torch.randperm(len(dataset)).tolist()\n",
        "        size_of_test = int(len(dataset) * 0.1)\n",
        "        size_of_main = len(dataset) - size_of_test\n",
        "        \n",
        "        dataset = torch.utils.data.Subset(dataset, indices[:-size_of_test])\n",
        "        self.dataset_test = torch.utils.data.Subset(dataset_test, indices[-size_of_test:])\n",
        "        self.dataset_train, self.dataset_val = torch.utils.data.random_split(dataset, [int(size_of_main*0.8), size_of_main - int(size_of_main*0.8)])\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        oct_train = DataLoader(self.dataset_train, batch_size=40, num_workers=4)\n",
        "        return oct_train\n",
        "    \n",
        "    def val_dataloader(self):\n",
        "        oct_val = DataLoader(self.dataset_val, batch_size=40, num_workers=4)\n",
        "        return oct_val\n",
        "    \n",
        "    def test_dataloader(self):\n",
        "        oct_test = DataLoader(self.dataset_test, batch_size=40, num_workers=4)\n",
        "        return oct_test\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr = 1e-3)\n",
        "        return optimizer\n",
        "\n",
        "    def loss_funtion(self, input, target):\n",
        "        return torch.sum((input - target) ** 2)\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y, _ = batch\n",
        "        input = self.forward(x)\n",
        "        loss = self.loss_funtion(input, y)\n",
        "\n",
        "        tensorboard_logs = {'train_loss': loss}\n",
        "        return {'loss': loss, 'log': tensorboard_logs}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y, _ = batch\n",
        "        input = self.forward(x)\n",
        "        loss = self.loss_funtion(input, y)\n",
        "        return {'val_loss': loss}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        # OPTIONAL\n",
        "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
        "        tensorboard_logs = {'val_loss': avg_loss}\n",
        "        return {'val_loss': avg_loss, 'log': tensorboard_logs}\n",
        "    \n",
        "    def test_step(self, batch, batch_idx):\n",
        "        # OPTIONAL\n",
        "        x, y, _ = batch\n",
        "        input = self.forward(x)\n",
        "        return {'test_loss': self.loss_funtion(input, y)}\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        # OPTIONAL\n",
        "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
        "        logs = {'test_loss': avg_loss}\n",
        "        return {'avg_test_loss': avg_loss, 'log': logs, 'progress_bar': logs}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0sC0M0mc3pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content\"\n",
        "cnn_oct = CNNcheck(types = 'cnn')\n",
        "# most basic trainer, uses good defaults (1 gpu)\n",
        "trainer = pl.Trainer(gpus=1,profiler=True,\n",
        "                     #auto_lr_find=True, #set hparams\n",
        "                     gradient_clip_val=0.5,\n",
        "                     check_val_every_n_epoch=5,\n",
        "                     #early_stop_callback=True,\n",
        "                     max_epochs = 600,\n",
        "                     #min_epochs=400,\n",
        "                     progress_bar_refresh_rate = 12)    \n",
        "trainer.fit(cnn_oct)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6KHoDZ8dBij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer.test()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqlVrKUMdBlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}